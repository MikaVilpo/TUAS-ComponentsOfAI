{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base directory\n",
    "base_dir = os.getcwd()  # Get the current working directory\n",
    "\n",
    "# Construct the path to the dataset\n",
    "dataset_dir = os.path.join(base_dir, 'dataset')\n",
    "\n",
    "# Construct the path to the training directory\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "\n",
    "# Construct the paths to each subdirectory for training\n",
    "train_headtop_dir = os.path.join(train_dir, 'headtop')\n",
    "train_helmet_dir = os.path.join(train_dir, 'helmet')\n",
    "train_hoodie_dir = os.path.join(train_dir, 'hoodie')\n",
    "train_no_headware_dir = os.path.join(train_dir, 'no_headwear')\n",
    "\n",
    "# Print the total number of images in each training subdirectory\n",
    "if os.path.exists(train_headtop_dir):\n",
    "    print('Total training headtop images:', len(os.listdir(train_headtop_dir)))\n",
    "else:\n",
    "    print(f\"Directory {train_headtop_dir} does not exist\")\n",
    "\n",
    "if os.path.exists(train_helmet_dir):\n",
    "    print('Total training helmet images:', len(os.listdir(train_helmet_dir)))\n",
    "else:\n",
    "    print(f\"Directory {train_helmet_dir} does not exist\")\n",
    "\n",
    "if os.path.exists(train_hoodie_dir):\n",
    "    print('Total training hoodie images:', len(os.listdir(train_hoodie_dir)))\n",
    "else:\n",
    "    print(f\"Directory {train_hoodie_dir} does not exist\")\n",
    "\n",
    "if os.path.exists(train_no_headware_dir):\n",
    "    print('Total training no headware images:', len(os.listdir(train_no_headware_dir)))\n",
    "else:\n",
    "    print(f\"Directory {train_no_headware_dir} does not exist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the path to the validation directory\n",
    "val_dir = os.path.join(dataset_dir, 'val')\n",
    "\n",
    "# Construct the paths to each subdirectory for validation\n",
    "val_headtop_dir = os.path.join(val_dir, 'headtop')\n",
    "val_helmet_dir = os.path.join(val_dir, 'helmet')\n",
    "val_hoodie_dir = os.path.join(val_dir, 'hoodie')\n",
    "val_no_headware_dir = os.path.join(val_dir, 'no_headwear')\n",
    "\n",
    "# Print the total number of images in each validation subdirectory\n",
    "if os.path.exists(val_headtop_dir):\n",
    "    print('Total validation headtop images:', len(os.listdir(val_headtop_dir)))\n",
    "else:\n",
    "    print(f\"Directory {val_headtop_dir} does not exist\")\n",
    "\n",
    "if os.path.exists(val_helmet_dir):\n",
    "    print('Total validation helmet images:', len(os.listdir(val_helmet_dir)))\n",
    "else:\n",
    "    print(f\"Directory {val_helmet_dir} does not exist\")\n",
    "\n",
    "if os.path.exists(val_hoodie_dir):\n",
    "    print('Total validation hoodie images:', len(os.listdir(val_hoodie_dir)))\n",
    "else:\n",
    "    print(f\"Directory {val_hoodie_dir} does not exist\")\n",
    "\n",
    "if os.path.exists(val_no_headware_dir):\n",
    "    print('Total validation no headware images:', len(os.listdir(val_no_headware_dir)))\n",
    "else:\n",
    "    print(f\"Directory {val_no_headware_dir} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Only rescale the images\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,  # Use the validation directory\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Change to categorical for multi-class classification\n",
    ")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the simplified model with MaxPooling2D and Dropout\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile multi-class classification model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Model training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in the native Keras format\n",
    "model_path = os.path.join(base_dir, 'model.keras')  # Construct the file path\n",
    "model.save(model_path)  # Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base directory\n",
    "script_dir = os.getcwd()  # Get the current working directory\n",
    "\n",
    "# Load your pre-trained model\n",
    "# Replace 'path/to/your/model.keras' with the actual path to your model file\n",
    "model_path = os.path.join(script_dir, 'model.keras')\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Create a Tkinter root window (it will be hidden)\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "# Open a file dialog and select files\n",
    "file_paths = filedialog.askopenfilenames()\n",
    "\n",
    "# Define the target size for the images (should match the input size of the model)\n",
    "target_size = (300,300)\n",
    "\n",
    "for path in file_paths:\n",
    "    # Predicting images\n",
    "    img = image.load_img(path, target_size=target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    \n",
    "    # Assuming the model outputs probabilities for each class\n",
    "    class_index = np.argmax(classes[0])\n",
    "    class_labels = ['Headtop', 'Helmet', 'Hoodie', 'No headwear']  \n",
    "    print(f\"{path} is a {class_labels[class_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base directory\n",
    "script_dir = os.getcwd()  # Get the current working directory\n",
    "\n",
    "# Load your pre-trained model\n",
    "# Replace 'path/to/your/model.keras' with the actual path to your model file\n",
    "model_path = os.path.join(script_dir, 'model.keras')\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['Headtop', 'Helmet', 'Hoodie', 'No headwear']\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)  # 0 is the default camera\n",
    "\n",
    "# Define the target size for the images\n",
    "target_size = (300, 300)\n",
    "\n",
    "print(\"Press 'q' to exit the video feed.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture video frame. Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Preprocess the frame\n",
    "        resized_frame = cv2.resize(frame, target_size)  # Resize to match model input\n",
    "        img_array = np.expand_dims(resized_frame, axis=0) / 255.0  # Normalize and add batch dimension\n",
    "\n",
    "        # Make prediction\n",
    "        predictions = model.predict(img_array)\n",
    "        class_index = np.argmax(predictions[0])\n",
    "        prediction_label = class_labels[class_index]\n",
    "        confidence = predictions[0][class_index] * 100\n",
    "\n",
    "        # Display the prediction on the frame\n",
    "        cv2.putText(frame, f\"{prediction_label} ({confidence:.2f}%)\", \n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow('Hat Detection', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nProgram interrupted by the user. Exiting...\")\n",
    "\n",
    "finally:\n",
    "    # Release the webcam and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Resources released, video window closed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
