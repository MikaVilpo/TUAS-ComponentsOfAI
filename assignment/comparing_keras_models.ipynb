{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e19b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0, Xception, ResNet50V2, EfficientNetB2, DenseNet201, InceptionV3, ConvNeXtTiny\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845c38e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3919 files belonging to 4 classes.\n",
      "Found 395 files belonging to 4 classes.\n",
      "Found 379 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, (224, 224)) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Load datasets using tf.data pipeline\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/train',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ").map(preprocess_image).cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/val',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ").map(preprocess_image).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/test',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ").map(preprocess_image).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9844ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def trainModel(base_model, label):\n",
    "\n",
    "    base_model.trainable = False  # Freeze the base model initially\n",
    "    \n",
    "    # Add task-specific layers with improved Dropout\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3), \n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5), \n",
    "        layers.Dense(4, activation='softmax')  # Adjust number of classes accordingly\n",
    "    ])\n",
    "    \n",
    "    # Implement Learning Rate Decay\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True\n",
    "    )\n",
    "    \n",
    "    # Compile the model with improved learning rate tuning\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss='sparse_categorical_crossentropy',  \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    checkpoint_callback = ModelCheckpoint(label + \"_best.keras\", save_best_only=True, monitor=\"val_loss\", verbose=1)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=15,\n",
    "        callbacks=[early_stopping, checkpoint_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fine-tune the entire model\n",
    "    base_model.trainable = True  # Unfreeze the base model\n",
    "    \n",
    "    # Recompile model with a lower learning rate for fine-tuning\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='sparse_categorical_crossentropy',  # Or categorical if using one-hot\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Fine-tune the model with a new EarlyStopping instance\n",
    "    history_fine = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=15,\n",
    "        callbacks=[early_stopping, checkpoint_callback],  # New callbacks\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "   \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds, verbose=1)\n",
    "\n",
    "    print(f\"Model: {label}\")\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52eb15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6601 - accuracy: 0.7425\n",
      "Epoch 1: val_loss improved from inf to 0.38757, saving model to DenseNet201_best.keras\n",
      "123/123 [==============================] - 460s 4s/step - loss: 0.6601 - accuracy: 0.7425 - val_loss: 0.3876 - val_accuracy: 0.8633\n",
      "Epoch 2/15\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.8528\n",
      "Epoch 2: val_loss improved from 0.38757 to 0.36738, saving model to DenseNet201_best.keras\n",
      "123/123 [==============================] - 450s 4s/step - loss: 0.4091 - accuracy: 0.8528 - val_loss: 0.3674 - val_accuracy: 0.8861\n",
      "Epoch 3/15\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.8637\n",
      "Epoch 3: val_loss improved from 0.36738 to 0.36225, saving model to DenseNet201_best.keras\n",
      "123/123 [==============================] - 417s 3s/step - loss: 0.3753 - accuracy: 0.8637 - val_loss: 0.3623 - val_accuracy: 0.8861\n",
      "Epoch 4/15\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.8824\n",
      "Epoch 4: val_loss improved from 0.36225 to 0.34959, saving model to DenseNet201_best.keras\n",
      "123/123 [==============================] - 427s 3s/step - loss: 0.3403 - accuracy: 0.8824 - val_loss: 0.3496 - val_accuracy: 0.9013\n",
      "Epoch 5/15\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.8865\n",
      "Epoch 5: val_loss did not improve from 0.34959\n",
      "123/123 [==============================] - 491s 4s/step - loss: 0.3109 - accuracy: 0.8865 - val_loss: 0.3629 - val_accuracy: 0.8886\n",
      "Epoch 6/15\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.8844\n",
      "Epoch 6: val_loss did not improve from 0.34959\n",
      "123/123 [==============================] - 470s 4s/step - loss: 0.3144 - accuracy: 0.8844 - val_loss: 0.3822 - val_accuracy: 0.8785\n",
      "Epoch 7/15\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.8926\n",
      "Epoch 7: val_loss improved from 0.34959 to 0.34736, saving model to DenseNet201_best.keras\n",
      "123/123 [==============================] - 472s 4s/step - loss: 0.2912 - accuracy: 0.8926 - val_loss: 0.3474 - val_accuracy: 0.8987\n",
      "Epoch 8/15\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.8931\n",
      "Epoch 8: val_loss improved from 0.34736 to 0.33690, saving model to DenseNet201_best.keras\n",
      "123/123 [==============================] - 531s 4s/step - loss: 0.2963 - accuracy: 0.8931 - val_loss: 0.3369 - val_accuracy: 0.9089\n",
      "Epoch 9/15\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9076"
     ]
    }
   ],
   "source": [
    "#https://keras.io/api/applications/\n",
    "# Load Pretrained Models, train and test them\n",
    "\n",
    "efficientNetB2_model = EfficientNetB2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "trainModel(efficientNetB2_model, \"EfficientNetB2\")\n",
    "\n",
    "resNet50V2_model = ResNet50V2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "trainModel(resNet50V2_model, \"ResNet50V2\")\n",
    "\n",
    "xception_model = Xception(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "trainModel(xception_model, \"Xception\")\n",
    "\n",
    "mobileNetV2_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "trainModel(mobileNetV2_model, \"MobileNetV2\")\n",
    "\n",
    "efficientNetB0_model = EfficientNetB0(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "trainModel(mobileNetV2_model, \"EfficientNetB0\")\n",
    "\n",
    "denseNet201_model = DenseNet201(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "trainModel(denseNet201_model, \"DenseNet201\")\n",
    "\n",
    "inceptionV3_model = InceptionV3(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "trainModel(inceptionV3_model, \"InceptionV3\")\n",
    "\n",
    "convNeXtTiny_model = ConvNeXtTiny(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "trainModel(convNeXtTiny_model, \"ConvNeXtTiny\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23517b4-9c52-4e77-ae9a-d33f7fce9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model: ResNet50V2\n",
    "Test Loss: 0.2777522802352905\n",
    "Test Accuracy: 0.9287598729133606\n",
    "\n",
    "Model: Xception\n",
    "Test Loss: 0.18646970391273499\n",
    "Test Accuracy: 0.9472295641899109\n",
    "\n",
    "Model: MobileNetV2\n",
    "Test Loss: 1.1013202667236328\n",
    "Test Accuracy: 0.831134557723999\n",
    "\n",
    "Model: EfficientNetB0\n",
    "Test Loss: 1.2719537019729614\n",
    "Test Accuracy: 0.8205804824829102\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ed0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
